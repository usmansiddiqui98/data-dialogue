{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47551261-d633-49dc-be52-1400e176ceb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c73e5e-ed5d-4d53-b1d6-1e78477c0c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/raw/reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f53fcc-680f-4cf5-ba52-ab7f7ef2dfe4",
   "metadata": {},
   "source": [
    "## Sentiment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757a4db-b398-461f-834c-ffd4464ddc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of reviews for each sentiment\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "data = go.Bar(x=sentiment_counts.index, y=sentiment_counts.values)\n",
    "layout = go.Layout(title='Distribution of Sentiment Labels')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f6014-e190-4a6c-8ca0-5dd101a5834c",
   "metadata": {
    "tags": []
   },
   "source": [
    "As shown, the data set is slightly imbalanced with 4030 positve sentiments and 1414 negative sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c540a-b089-45e4-b51c-d8914cbf505b",
   "metadata": {},
   "source": [
    "## Recency of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493701e0-f09f-4707-a64e-bae7b4a059aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "reviews_by_date = df.groupby(pd.Grouper(key='Time', freq='M')).size()\n",
    "\n",
    "data = go.Scatter(x=reviews_by_date.index, y=reviews_by_date.values, mode='lines')\n",
    "layout = go.Layout(title='Number of Reviews Over Time')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd5008-cfde-4a91-891a-c19ee18b10a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_counts = df.groupby(['Time', 'Sentiment']).size().reset_index(name='count')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=sentiment_counts[sentiment_counts['Sentiment'] == 'positive']['Time'], \n",
    "                         y=sentiment_counts[sentiment_counts['Sentiment'] == 'positive']['count'], \n",
    "                         mode='lines', name='Positive'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sentiment_counts[sentiment_counts['Sentiment'] == 'negative']['Time'], \n",
    "                         y=sentiment_counts[sentiment_counts['Sentiment'] == 'negative']['count'], \n",
    "                         mode='lines', name='Negative'))\n",
    "fig.update_layout(title='Sentiment Counts Over Time', xaxis_title='Time', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a71f5f-5e45-4a8f-8906-45cc2daa197e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_trace = go.Histogram(x=df[df['Sentiment'] == 'positive']['Time'], \n",
    "                              name='Positive', \n",
    "                              marker_color='#00FF00')\n",
    "negative_trace = go.Histogram(x=df[df['Sentiment'] == 'negative']['Time'], \n",
    "                              name='Negative', \n",
    "                              marker_color='#FF0000')\n",
    "fig = go.Figure()\n",
    "fig.add_trace(positive_trace)\n",
    "fig.add_trace(negative_trace)\n",
    "fig.update_layout(title='Distribution of Sentiment vs Time', xaxis_title='Time', yaxis_title='Sentiment Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3b5cf-2e04-49d5-822b-f399656055fb",
   "metadata": {},
   "source": [
    "## Exploring reviews columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b74c08-06a5-4c62-9f3d-807fae0dcda9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review_length'] = df['Text'].apply(len)\n",
    "fig = go.Figure(data=[go.Histogram(x=df['review_length'])])\n",
    "fig.update_layout(\n",
    "    title=\"Review Length Distribution\",\n",
    "    xaxis_title=\"Review Length\",\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6e387-acb1-4e1c-947a-6a1ff6d91d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_text = \" \".join(df['Text'])\n",
    "# remove <br> tags from the text\n",
    "reviews_text = re.sub(r'<br\\s?\\/?>', ' ', reviews_text)\n",
    "# remove punctuation from the text\n",
    "reviews_text = reviews_text.translate(str.maketrans('', '', string.punctuation))\n",
    "# remove stop words from the text\n",
    "sw = set(STOPWORDS)\n",
    "words = [w for w in reviews_text.split() if w.lower() not in sw]\n",
    "\n",
    "word_counts = Counter(words).most_common(50)\n",
    "fig = go.Figure([go.Bar(x=[w[0] for w in word_counts], y=[w[1] for w in word_counts])])\n",
    "fig.update_layout(title=\"Most Frequent Words\", xaxis_title=\"Word\", yaxis_title=\"Frequency\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b155736-2f68-4fb6-9dba-aad18a99245d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# create a wordcloud of the most frequent words\n",
    "wordcloud = WordCloud(width=400, height=400, background_color=\"white\", stopwords=sw).generate(reviews_text)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69d343-4d91-4e8b-8c86-52f6fe9c1ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the most frequent bigrams and their counts, filtering out those that contain stop words\n",
    "bigrams = [b for b in zip(words[:-1], words[1:]) if b[0].lower() not in sw and b[1].lower() not in sw]\n",
    "bigram_counts = Counter(bigrams).most_common(20)\n",
    "fig = go.Figure([go.Bar(x=[\" \".join(b) for b in [w[0] for w in bigram_counts]], y=[w[1] for w in bigram_counts])])\n",
    "fig.update_layout(title=\"Most Frequent Bigrams\", xaxis_title=\"Bigram\", yaxis_title=\"Frequency\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65d45c-fd1c-4267-a64a-0154def9395c",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Amazon dataset \n",
    "- Mainly f&b/grocery products reviewing taste and quality of a product\n",
    "- Coffee, tea, peanut butter, hot chocolate are some of the products\n",
    "- More Positive sentiments than negative sentiments (products doing fairly well)\n",
    "- Date range of data is from 2017-2021 but the number of reviews really exploded in 2020-2021 (Relation with Covid and online shopping?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae15e3-19c8-498e-95f3-fa309157ceea",
   "metadata": {},
   "source": [
    "## Identify product genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14b703-fda5-4245-ae77-d6315816f458",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ddf33-7449-4516-bca4-fb4350e69f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to clean the text data\n",
    "def clean_text(text):\n",
    "    # remove <br> tags\n",
    "    text = re.sub(r'<br\\s?\\/?>', ' ', text)\n",
    "    # expand contractions\n",
    "    expanded_text = []\n",
    "    for word in text.split():\n",
    "      expanded_text.append(contractions.fix(word))  \n",
    "    expanded_text = ' '.join(expanded_text)\n",
    "    # make all words lower case\n",
    "    expanded_text = expanded_text.lower()\n",
    "    # remove punctuation\n",
    "    expanded_text = expanded_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # remove stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    stopwords_list.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "    words_clean = [word for word in expanded_text.split() if word.lower() not in stopwords_list]\n",
    "    return \" \".join(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb222d1-7b9c-4aa6-8063-13fc977cf8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_reviews'] = df['Text'].apply(clean_text)\n",
    "df['clean_review_length'] = df['clean_reviews'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f55182-17a9-4976-88df-ee6a9943a9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.to_csv('../../data/processed/cleaned_reviews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
