{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47551261-d633-49dc-be52-1400e176ceb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c73e5e-ed5d-4d53-b1d6-1e78477c0c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/cleaned_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9e2b9-cb29-4ffb-9475-6b86bf3e0084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freq_words(x, terms = 30):\n",
    "    all_words = ' '.join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "    # selecting top 20 most frequent words\n",
    "    d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d124613-9b65-4fa5-aa0e-efd97003184b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_words(df['clean_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8d084-2d03-4901-9952-93e3744a4b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_reviews = pd.Series(df['clean_reviews']).apply(lambda x: x.split())\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatization(texts, tags):# filter based on tags\n",
    "    output = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        output.append([token.lemma_ for token in doc if token.pos_ in tags])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4849122-dd5a-406c-b165-92e11a67459f",
   "metadata": {},
   "source": [
    "Filter text based on nouns and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190ea49-3be0-472b-a50b-50032e10f657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_2 = lemmatization(tokenized_reviews, tags =['NOUN', 'ADJ'] )\n",
    "print(reviews_2[1]) # print lemmatized review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205055b2-9db5-428c-a621-634f54ff81ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_words([item for sublist in reviews_2 for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf19378-7ef3-4553-8d71-a9ff913847e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Filter text based on nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e8d30-cf82-4db6-ace8-269865491901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_3 = lemmatization(tokenized_reviews, tags =['NOUN'] )\n",
    "print(reviews_3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086dbe9-ddbc-486d-b8d8-cc8f87956681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_words([item for sublist in reviews_3 for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759251b-69ad-4f12-bb36-f8c376638e36",
   "metadata": {
    "tags": []
   },
   "source": [
    "Filter text based on adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed01494-556b-4a28-9559-c426707e3b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_4 = lemmatization(tokenized_reviews, tags =['ADJ'] )\n",
    "print(reviews_4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7fa36-fd99-40e3-9f82-1320db204295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_words([item for sublist in reviews_4 for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1c156-b72f-4129-b480-b925efd98828",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSA modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a8905-1144-46b8-8a98-b534bd9276fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSAmodel(data, no_of_topics):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', \n",
    "    max_features= 1000, # keep top 1000 terms \n",
    "    max_df = 0.5, \n",
    "    smooth_idf=True)\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(X.shape)\n",
    "    svd_model = TruncatedSVD(n_components=no_of_topics, algorithm='randomized', n_iter=100, random_state=122)\n",
    "    svd_model.fit(X)\n",
    "    print(len(svd_model.components_))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    for i, comp in enumerate(svd_model.components_):\n",
    "        terms_comp = zip(terms, comp)\n",
    "        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "        print(\"Topic \"+str(i)+\": \")\n",
    "        sentence = \"\"\n",
    "        print(sorted_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b991efd-f7d6-45ba-8d05-23c4d0b46e5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LSA without pre-processing (using df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42de6c3-89c3-4c4d-9031-87831fc2c818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(df['clean_reviews'],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d810df-f1e0-4f61-a98b-c5d74bcc37ed",
   "metadata": {},
   "source": [
    "#### LSA with processed_reviews (both lemmatized nouns + adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae882869-d12d-484c-beaf-d4cae0dfb5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_nouns_reviews = [item for sublist in reviews_2 for item in sublist]\n",
    "LSAmodel(adj_nouns_reviews,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79017ee-f6b1-4806-9fe0-5b59efb589cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(adj_nouns_reviews,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef100f3-20a6-4b4c-a827-d26d91b33c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(adj_nouns_reviews,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7c087-dd3a-4e10-8591-e4983a9762bc",
   "metadata": {},
   "source": [
    "#### LSA with processed_reviews (lemmatized nouns only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab954ea-e407-4ae3-b2e2-0139ff6836fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nouns_reviews = [item for sublist in reviews_3 for item in sublist]\n",
    "LSAmodel(nouns_reviews,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b6946-668a-449b-89a1-7155fe50717d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(nouns_reviews,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57b278-ff6c-4b16-b8d9-4fe193b25882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(nouns_reviews,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810a57a-e0cb-40bb-a89b-f079ef64ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSAmodel(nouns_reviews,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05515fc5-6fce-4499-82f8-f41e1b8418d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LSA with processed_reviews (lemmatized adjs only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282a8d7-cead-40aa-9568-993cffcbe105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_reviews = [item for sublist in reviews_4 for item in sublist]\n",
    "LSAmodel(adj_reviews,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6a217-23e6-4d03-9930-e4f97075a39c",
   "metadata": {},
   "source": [
    "LSA assumes a Gaussian distribution of the terms in the documents, which may not be true for all problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f49891-ee9e-44b7-bd4e-59d6e68670b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LDA (1) using sklearn (do not run as the hyperparameter tuning takes very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323501cc-1b98-46b8-ab33-709f3f2983aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lda_sklearn(reviews, numtopics):\n",
    "    # create a CountVectorizer object\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "\n",
    "    # fit and transform the clean text data\n",
    "    X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "    # Materialize the sparse data\n",
    "    data_dense = X.todense()\n",
    "\n",
    "    # Compute Sparsicity \n",
    "    # Sparsicity is the percentage of non-zero datapoints in X\n",
    "    print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")\n",
    "\n",
    "    # create an LDA object and fit the data\n",
    "    lda = LatentDirichletAllocation(n_components=numtopics, random_state=42)\n",
    "    lda.fit(X)\n",
    "\n",
    "    # print the top words in each topic\n",
    "    feature_names = sorted(vectorizer.vocabulary_.keys())\n",
    "    topic_list = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        topic_complete = (\", \".join([feature_names[i] for i in topic.argsort()[:-15:-1]]))\n",
    "        print(topic_complete)\n",
    "        topic_list.append(topic_complete)\n",
    "        \n",
    "    # Log Likelyhood: Higher the better\n",
    "    print(\"Log Likelihood: \", lda.score(X))\n",
    "\n",
    "    # Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "    print(\"Perplexity: \", lda.perplexity(X))\n",
    "\n",
    "    # See model parameters\n",
    "    pprint.pprint(lda.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7448170-47ed-48e4-a0dc-cb9106b95f27",
   "metadata": {},
   "source": [
    "Reviews_2 consist of both nouns and adjs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280df14-6280-4a6c-be54-5d1f0c184170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_2 consist of both nouns and adjs only\n",
    "adj_nouns_reviews = [item for sublist in reviews_2 for item in sublist]\n",
    "lda_sklearn(adj_nouns_reviews,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f8238-b95c-4217-a961-f376b21fab98",
   "metadata": {
    "tags": []
   },
   "source": [
    "Reviews_3 consist of both nouns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cca35-cac6-44bd-9da5-1973e95776aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_reviews = [item for sublist in reviews_3 for item in sublist]\n",
    "lda_sklearn(nouns_reviews,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c05c42-7ed0-442c-a9c6-afe769a4ae15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_best_model(reviews):\n",
    "    # create a CountVectorizer object\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "\n",
    "    # fit and transform the clean text data\n",
    "    X = vectorizer.fit_transform(reviews)\n",
    "    \n",
    "    # Define Search Param\n",
    "    search_params = {'n_components': [3,4,5,6,7], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "    # Init the Model\n",
    "    lda = LatentDirichletAllocation()\n",
    "\n",
    "    # Init Grid Search Class\n",
    "    model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "    # Do the Grid Search\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Best Model\n",
    "    best_lda_model = model.best_estimator_\n",
    "\n",
    "    # Model Parameters\n",
    "    print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "    # Log Likelihood Score\n",
    "    print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "    # Perplexity\n",
    "    print(\"Model Perplexity: \", best_lda_model.perplexity(X))\n",
    "    \n",
    "    # Get Log Likelyhoods from Grid Search Output\n",
    "    n_topics = [3,4,5,6,7,8]\n",
    "    log_likelyhoods_5 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(model.cv_results_['params']) if gscore['learning_decay']==0.5]\n",
    "    log_likelyhoods_7 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(model.cv_results_['params']) if gscore['learning_decay']==0.7]\n",
    "    log_likelyhoods_9 = [round(model.cv_results_['mean_test_score'][index]) for index, gscore in enumerate(model.cv_results_['params']) if gscore['learning_decay']==0.9]\n",
    "\n",
    "    # Show graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "    plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "    plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "    plt.title(\"Choosing Optimal LDA Model\")\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Log Likelyhood Scores\")\n",
    "    plt.legend(title='Learning decay', loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dad160-7b8a-4737-b118-e44645c12a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_best_model(adj_nouns_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632ea05-47c7-4288-989e-43ae3dae0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_best_model(nouns_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16f344-7ebf-43e9-bc6e-79f8032ca757",
   "metadata": {},
   "source": [
    "A model with higher log-likelihood and lower perplexity (exp(-1. * log-likelihood per word)) is considered to be good.\n",
    "On a different note, perplexity might not be the best measure to evaluate topic models because it doesn’t consider the context and semantic associations between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a4bd9-981b-43a5-a69f-3cf0ff8e1ce2",
   "metadata": {},
   "source": [
    "It can be concluded that hyperparameter tuning has not been effective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac57663-9be8-4bef-bd58-5f0358415c1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LDA (2) using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03f251-dd4e-4993-822b-28f5e2352930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lda_gensim(cleaned_reviews, num_topics):\n",
    "    # create the id2word dictionary\n",
    "    id2word = corpora.Dictionary(cleaned_reviews)\n",
    "\n",
    "    # create the corpus\n",
    "    corpus = [id2word.doc2bow(tokens) for tokens in cleaned_reviews]\n",
    "\n",
    "    # create the LDA model\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, passes=10)\n",
    "    for element in lda_model.print_topics():\n",
    "        print('Topic ' + str(element[0]))\n",
    "        print(element[1])\n",
    "    return lda_model, corpus, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e60cca-5e74-4fbb-8a8c-de108fafb6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lda_viz(lda_model, corpus, id2word):\n",
    "    # visualize the topics using pyLDAvis\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eac72f-78ff-41af-8726-2b1c2fec45e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_1 refers to full text\n",
    "reviews_1 = []\n",
    "for review in df['clean_reviews']:\n",
    "    reviews_1.append(word_tokenize(review))\n",
    "    \n",
    "model, corpus, id2_word = lda_gensim(reviews_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351cfbe-4a0a-4b5c-b2e8-745052f959ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word = lda_gensim(reviews_1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fed3f-a448-42fa-84a4-f46a2cc04d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word = lda_gensim(reviews_1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5636c-69e5-483f-ae65-c033a0c7817c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_2 consist of both nouns and adjs only\n",
    "model, corpus, id2_word = lda_gensim(reviews_2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd23c7b-2c17-4b2d-91f4-092b723d7121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word = lda_gensim(reviews_2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d9270-214f-4e06-8a2d-624a72edd71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word = lda_gensim(reviews_2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a85c0-277c-4e52-bc6b-eba8494c00bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word = lda_gensim(reviews_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af849b2-4fbc-4576-83d8-bcc2c886c76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_3 consist of nouns only\n",
    "model, corpus, id2_word =lda_gensim(reviews_3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10542c94-a5b2-49de-9d7b-dd4b4ffd88b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a811a0-ca96-435e-8b73-56f875a2e95e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04011ee-1275-4e95-9b32-a3d8d9a9b353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056d2e3-caef-44d7-a1fc-b3f4939339d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_4 consist of adjs only\n",
    "model, corpus, id2_word =lda_gensim(reviews_4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34462e4e-5978-4608-9329-dce9e5cbc1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e9ce1-ce0f-4208-ad61-de0482fbb41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1866f6a-6c95-44ad-9719-662dda1e6fc0",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "From using texts filtered on nouns only, We can narrow down texts in to 6 main topics:\n",
    "- Pets\n",
    "- Baby\n",
    "- Snacks\n",
    "- Beverages\n",
    "- Protein/Food\n",
    "- Condiments/Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1de056-259b-4580-8341-ebef99b31a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, corpus, id2_word =lda_gensim(reviews_3, 6) # texts based on nouns only\n",
    "lda_viz(model, corpus, id2_word )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84577e1a-cbfa-43f2-aa0d-6f2944cfcc32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8301e-5b78-4250-b28f-3fc6ff412839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03bdeb-b238-49be-b352-bf45508e87aa",
   "metadata": {},
   "source": [
    "#### Pet products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea38d98-3205-46e4-b9e4-00709c559eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pet_entities(text):\n",
    "    doc = nlp(text)\n",
    "    pet_entities = []\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"ANIMAL\" or \"pet\" in entity.text.lower() or \"dog\" in entity.text.lower() or \"cat\" in entity.text.lower():\n",
    "            pet_entities.append(entity.text)\n",
    "    return pet_entities\n",
    "\n",
    "# apply the extract_pet_entities function to the reviews column\n",
    "df['pet_entities'] = df['clean_reviews'].apply(extract_pet_entities)\n",
    "\n",
    "# print the unique pet-related entities that were extracted\n",
    "pet_entities = set([entity for row in df['pet_entities'] for entity in row])\n",
    "print(pet_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149179d-7077-46a6-9556-3cbb8c68b700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(pet_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c693d3-e198-44b4-af8c-036b795dfc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['pet_entities'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71db254-441f-4bc0-bdfa-30aed79bac43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_product_entities(text):\n",
    "    doc = nlp(text)\n",
    "    product_entities = []\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"PRODUCT\" or \"coffee\" in entity.text.lower() or \"tea\" in entity.text.lower() or \"caffeine\" in entity.text.lower():\n",
    "            product_entities.append(entity.text)\n",
    "    return product_entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf04fc-51c8-4445-b0de-ad8863db7aaa",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Explore the brand these reviews are for\n",
    "- Knowing the domain that this dataset is for, use transfer learning to build a relevant pre-trained model to improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
