{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab455e-2612-484f-b755-99af3d7321f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, f1_score\n",
    "from src.data.feature_engineering import FeatureEngineer\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8872247-0c24-4700-a9af-e28a174685ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/raw/reviews.csv\", parse_dates=['Time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec39b68-e73d-4538-a0ae-a203d3ff156a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    \"a\",\n",
    "    \"an\",\"and\",\n",
    "    \"are\",\n",
    "    \"as\",\n",
    "    \"at\",\n",
    "    \"be\",\n",
    "    \"by\",\n",
    "    \"can\",\n",
    "    \"did\",\n",
    "    \"do\",\n",
    "    \"for\",\n",
    "    \"from\",\n",
    "    \"had\",\n",
    "    \"has\",\n",
    "    \"have\",\n",
    "    \"he\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"if\",\n",
    "    \"in\",\n",
    "    \"is\",\n",
    "    \"it\",\n",
    "    \"its\",\n",
    "    \"may\",\n",
    "    \"of\",\n",
    "    \"on\",\n",
    "    \"or\",\n",
    "    \"shall\",\n",
    "    \"should\",\n",
    "    \"since\",\n",
    "    \"so\",\n",
    "    \"some\",\n",
    "    \"such\",\n",
    "    \"that\",\n",
    "    \"the\",\n",
    "    \"their\",\n",
    "    \"them\",\n",
    "    \"then\",\n",
    "    \"there\",\n",
    "    \"these\",\n",
    "    \"they\",\n",
    "    \"this\",\n",
    "    \"those\",\n",
    "    \"to\",\n",
    "    \"was\",\n",
    "    \"we\",\n",
    "    \"were\",\n",
    "    \"when\",\n",
    "    \"where\",\n",
    "    \"which\",\n",
    "    \"while\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"whose\",\n",
    "    \"will\",\n",
    "    \"with\",\n",
    "    \"would\",\n",
    "    \"you\",\n",
    "    \"your\",\n",
    "    \"yours\",\n",
    "    \"about\",\n",
    "    \"above\",\n",
    "    \"across\",\n",
    "    \"after\",\n",
    "    \"against\",\n",
    "    \"along\",\n",
    "    \"among\",\n",
    "    \"around\",\n",
    "    \"before\",\n",
    "    \"behind\",\n",
    "    \"below\",\n",
    "    \"beneath\",\n",
    "    \"beside\",\n",
    "    \"between\",\n",
    "    \"beyond\",\n",
    "    \"during\",\n",
    "    \"inside\",\n",
    "    \"into\",\n",
    "    \"near\",\n",
    "    \"outside\",\n",
    "    \"over\",\n",
    "    \"through\",\n",
    "    \"under\",\n",
    "    \"upon\",\n",
    "    \"within\",\n",
    "    \"without\",\n",
    "    \"been\",\n",
    "    \"having\",\n",
    "    \"once\",\n",
    "    \"other\",\n",
    "    \"until\",\n",
    "    \"own\",\n",
    "    \"each\",\n",
    "    \"every\",\n",
    "    \"any\",\n",
    "    \"all\",\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"four\",\n",
    "    \"five\",\n",
    "    \"six\",\n",
    "    \"seven\",\n",
    "    \"eight\",\n",
    "    \"nine\",\n",
    "    \"ten\",\n",
    "    \"many\",\n",
    "    \"several\",\n",
    "    \"few\",\n",
    "    \"how\",\n",
    "    \"anyway\",\n",
    "    \"however\",\n",
    "    \"just\",\n",
    "    \"my\"\n",
    "]\n",
    "stopwords = list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a8018-2d04-4570-8f43-b1eaa1758509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, stopwords):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W|\\d+', ' ', text)\n",
    "    \n",
    "    # Tokenize words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Reconstruct the text\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df626e05-34ca-47f8-8d58-a62b789587be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the reviews and feature engineer\n",
    "pre_processed_df = df.copy()\n",
    "pre_processed_df['cleaned_text'] = pre_processed_df['Text'].apply(lambda x: preprocess_text(x, stopwords))\n",
    "pre_processed_df['Sentiment'] = pre_processed_df['Sentiment'].apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "pre_processed_df = pre_processed_df.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b16769-3ad1-43b6-bb1c-e30b38bfd463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451fd55-c512-4b1a-996c-793f4d3a2a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_engineer = FeatureEngineer(pre_processed_df)\n",
    "feature_engineer.add_features()\n",
    "feature_engineered_df = feature_engineer.feature_engineered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e9876-1635-4d5e-8c64-e8065b02c845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9e6f7-b802-4f57-9d83-23a63b2e98ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = feature_engineered_df.drop(['sentiment', 'time', 'polarity'], axis=1)\n",
    "\n",
    "y = feature_engineered_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4263, stratify=y)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_text'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_text'])\n",
    "\n",
    "X_train_tfidf = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_test_tfidf = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "X_train_clean = X_train.drop(['cleaned_text', 'text', 'uppercase_words'], axis=1)\n",
    "X_test_clean = X_test.drop(['cleaned_text', 'text', 'uppercase_words'], axis=1)\n",
    "\n",
    "X_train_concat = pd.concat([X_train_clean, X_train_tfidf], axis=1)\n",
    "X_test_concat = pd.concat([X_test_clean, X_test_tfidf], axis=1)\n",
    "\n",
    "X_train_concat = X_train_concat.loc[:, ~X_train_concat.columns.duplicated()].copy()\n",
    "X_test_concat = X_test_concat.loc[:, ~X_test_concat.columns.duplicated()].copy()\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_clf.fit(X_train_concat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08f9a9-f04e-4e75-b5ae-0eaca5eacc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = xgb_clf.predict(X_test_concat)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"f1-score:\", f1_score)\n",
    "print(\"Confusion Matrix: \\n\", conf_matrix)\n",
    "print(\"Classification Report: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e371f66-5908-4f87-9115-19022afa3af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"For this XGBoost model, the AUC score is: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184027d0-3201-4a4f-b401-aafc5b0b073b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "plot_importance(xgb_clf, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d699931-1982-41c2-b99e-376e3006ffe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4263)\n",
    "\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'subsample': [0.5, 0.8, 1],\n",
    "#     'colsample_bytree': [0.5, 0.8, 1],\n",
    "# }\n",
    "\n",
    "# # Train the XGBoost classifier\n",
    "# xgb_clf_tuned = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb_clf_tuned,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=skf,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best accuracy score found: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f40df-6e7a-457e-b5fb-01943c2a0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_tuned = grid_search.predict(X_test)\n",
    "# accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "# precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "# recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "# conf_matrix_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "# class_report_tuned = classification_report(y_test, y_pred_tuned)\n",
    "\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_tuned)\n",
    "# print(\"Precision:\", precision_tuned)\n",
    "# print(\"Recall:\", recall_tuned)\n",
    "# print(\"Confusion Matrix:\", conf_matrix)\n",
    "# print(\"Classification Report:\", class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
