{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312c9d8-b7f7-49a7-988a-1aa6396b0601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b90e30-8982-42ff-ab14-f2c817cfe531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/raw/reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85045a-07e1-4b36-999f-ca828b6933c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,y = df['Text'].values,df['Sentiment'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y, random_state = 4263)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3279a-ac47-4217-9fd1-cafe9af42497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32df19-e89a-4b54-8fc8-7e14021db882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def create_word_list(x_train):\n",
    "    word_list = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split(' '):\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "    return word_list\n",
    "word_list = create_word_list(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aca968-8f43-48e3-888f-186252d06228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(x_train, y_train, x_test, y_test):\n",
    "    corpus = Counter(word_list)\n",
    "    corpus_ = sorted(corpus.items(), key = lambda x: x[1], reverse=True)[:1000]\n",
    "    onehot_dict = {w[0]:i+1 for i, w in enumerate(corpus_)}\n",
    "\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_test:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_test] \n",
    "    return np.array(final_list_train, dtype = 'object'), np.array(encoded_train),np.array(final_list_test, dtype = 'object'), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63264aa-7fff-43f2-9777-005b1091e45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tokenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d790c-ff2c-4930-8d4c-e4501df77c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rev_len = [len(i) for i in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83f298-d4da-4177-adf9-4aaa25fcf71c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padding(sents, seq_len):\n",
    "    features = np.zeros((len(sents), seq_len), dtype = int)\n",
    "    for i, rev in enumerate(sents):\n",
    "        if len(rev) != 0:\n",
    "            features[i, -len(rev):] = np.array(rev)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dc1e8-ca93-4e5f-b206-db552103300a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we have very less number of reviews of length > 30, so we will take review up till length 50 only\n",
    "x_train_pad = padding(x_train, 50)\n",
    "x_test_pad = padding(x_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d334e09-d6a2-48e2-8ba1-0f19028c87b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# batch size\n",
    "batch_size = 50\n",
    "\n",
    "# shuffle data\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size = batch_size, drop_last = True)\n",
    "test_loader = DataLoader(test_data, shuffle= True, batch_size = batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44514987-d581-4d60-a1c8-9259d4c5b5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "#     print(len(batch))\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(batch[0])\n",
    "    print(batch[1])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1dd412-e599-4d57-9edb-4c3586e2717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain one batch\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print(f\"Size of Batch {sample_x.size()}\")\n",
    "print(f\"Sample input {sample_x}\")\n",
    "print(f\"Sample output {sample_y}\")\n",
    "# obtain one batch of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b692f-4fd7-4af8-85c4-74f0a45e796f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob = 0.5):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        \n",
    "        self.no_layers = no_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  \n",
    "        \n",
    "        #LSTM\n",
    "        self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = self.hidden_dim, num_layers = no_layers, batch_first=True)\n",
    "        \n",
    "        #dropout layers\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        #linear and Sigmoid layer\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # we just passed a batch\n",
    "        batch_size = x.size(0) # batch size -> B\n",
    "        #embed shape -> [B, max_len, embed_dim]\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        \n",
    "        # drop out and fully connected\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid \n",
    "        \n",
    "        sig_out = self.sig(out)\n",
    "        #reshape to batch size first\n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        \n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        # create hidden state and cell state tensors with size [no_layers x batch_size x hidden_dim]\n",
    "        \n",
    "        hidden_state = torch.zeros((self.no_layers, batch_size, self.hidden_dim))\n",
    "        cell_state = torch.zeros((self.no_layers, batch_size, self.hidden_dim))\n",
    "        hidden = (hidden_state, cell_state)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7744784-7dba-4143-bd47-c7c8ffc9299f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_layers = 2 # no of layers in lstm\n",
    "vocab_size = len(vocab) + 1 # extra for 0 (padding symbol)\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "model = SentimentLSTM(no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob = 0.5)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789871c4-daa6-46ca-84ee-492a4b86479e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss and optimization features\n",
    "\n",
    "lr = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "# accuracy function\n",
    "def accuracy(pred, label):\n",
    "    pred =torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85de28b-7cae-4154-8037-5b10d9066960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip = 5\n",
    "epochs = 5\n",
    "test_loss_min = np.Inf\n",
    "epoch_tr_loss, epoch_tst_loss = [], []\n",
    "epoch_tr_acc, epoch_tst_acc = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    train_acc = 0\n",
    "    h = model.init_hidden(batch_size)\n",
    "    model.train()\n",
    "    # processing each batch\n",
    "    for x, y in train_loader:\n",
    "        x, y = x, y\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        model.zero_grad()\n",
    "        output, h = model(x, h)\n",
    "        \n",
    "        #calculate loss\n",
    "        \n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        #acuracy\n",
    "        \n",
    "        acc = accuracy(output, y)\n",
    "        \n",
    "        train_acc += acc\n",
    "        #clip_Grad_norm clips the grad or simply prevents exploding of gradient\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_h = model.init_hidden(batch_size)\n",
    "    test_loss = []\n",
    "    test_acc = 0\n",
    "    model.eval()\n",
    "    for x, y in test_loader:\n",
    "        x, y = x, y\n",
    "        test_h = tuple([each.data for each in test_h])\n",
    "        \n",
    "        output, test_h = model(x, test_h)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        acc = accuracy(output, y)\n",
    "        \n",
    "        test_acc += acc\n",
    "        \n",
    "    epoch_train_loss = np.mean(train_loss) # take average loss for each batch\n",
    "    epoch_test_loss = np.mean(test_loss)\n",
    "    \n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_tst_loss.append(epoch_test_loss)\n",
    "    \n",
    "    epoch_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    epoch_test_acc = test_acc / len(test_loader.dataset)\n",
    "    \n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_tst_acc.append(epoch_test_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} test_loss : {epoch_test_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} test_accuracy : {epoch_test_acc*100}')\n",
    "    if epoch_test_loss <= test_loss_min:\n",
    "        # torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min,epoch_test_loss))\n",
    "        test_loss_min = epoch_test_loss\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31b7b5-8702-43fa-b650-57746867bd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_tst_acc, label='Test Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_tst_loss, label='Test loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92b66d-ecff-4a96-b682-484c0e43a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() if preprocess_string(word) in vocab.keys()])\n",
    "    word_seq = np.expand_dims(word_seq, axis = 0)\n",
    "    print(word_seq)\n",
    "    pad = torch.from_numpy(padding(word_seq, 500))\n",
    "    \n",
    "    inputs = pad\n",
    "    batch_size = 1\n",
    "    h = model.init_hidden(batch_size)\n",
    "    output, h = model(inputs, h)\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c79dec-537f-409a-b3f3-52e097704eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['Sentiment'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15edede-d148-41b2-9683-2e7b9a253dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 44\n",
    "review, sentiment = df['Text'][index], df['Sentiment'][index]\n",
    "print(\"The statement is:\")\n",
    "print(review)\n",
    "print(\"==\"*25)\n",
    "print(f\"Original Sentiment is: {sentiment}\")\n",
    "print(\"==\"*25)\n",
    "pred = predict_sentiment(review)\n",
    "status = \"positive\" if pred > 0.5 else \"negative\"\n",
    "print(f\"Predicted Sentiment is {status} with probability of {pred}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474838a-7821-4d4c-92be-cb12cecea817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 70\n",
    "review, sentiment = df['Text'][index], df['Sentiment'][index]\n",
    "print(\"The statement is:\")\n",
    "print(review)\n",
    "print(\"==\"*25)\n",
    "print(f\"Original Sentiment is: {sentiment}\")\n",
    "print(\"==\"*25)\n",
    "pred = predict_sentiment(review)\n",
    "status = \"positive\" if pred > 0.5 else \"negative\"\n",
    "print(f\"Predicted Sentiment is {status} with probability of {pred}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fe7df-7520-4e3a-b326-6678677d547d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 62\n",
    "review, sentiment = df['Text'][index], df['Sentiment'][index]\n",
    "print(\"The statement is:\")\n",
    "print(review)\n",
    "print(\"==\"*25)\n",
    "print(f\"Original Sentiment is: {sentiment}\")\n",
    "print(\"==\"*25)\n",
    "pred = predict_sentiment(review)\n",
    "status = \"positive\" if pred > 0.5 else \"negative\"\n",
    "print(f\"Predicted Sentiment is {status} with probability of {pred}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b49bfc-0936-4e0a-8bab-69f4178f2549",
   "metadata": {},
   "source": [
    "Test on user generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b44bf-179f-4941-8d70-723e8da8146f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review = \"The product does seem to be different from what is show on the webite, it is also slightly expensive, would not buy again\"\n",
    "pred = predict_sentiment(review)\n",
    "status = \"positive\" if pred > 0.5 else \"negative\"\n",
    "print(f\"Predicted Sentiment is {status} with probability of {pred}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f5541-c878-404f-b294-35cc25e7fd88",
   "metadata": {
    "tags": []
   },
   "source": [
    "19 March 2023\n",
    "\n",
    "26% of data has negative sentiments\n",
    "74% of data has positive sentiments\n",
    "\n",
    "Data is slightly unbalanced and as seen from the model, the predicted probability for negative sentiment seems to be quite low. The model is good at classifying positive reviews but can be better on negative ones.\n",
    "\n",
    "Things to do next:\n",
    "- hyperparameter tuning \n",
    "- can tune threshold in which we determine whether sentiment is +/-, currently it is at 0.5\n",
    "- try other models such as XGboost which is great for unbalanced dataset\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6d290-1e1b-40be-9684-8a407dfeba03",
   "metadata": {
    "tags": []
   },
   "source": [
    "20 March 2023\n",
    "\n",
    "- reduce the length of reviews but changing the padding amount from 500 to 50 as most of the reviews are very short, this proved to improve the model significantly as the training/testing loss and accuracy improved and there is lesser overfitting\n",
    "\n",
    "- Model highest train accuracy is 88% and test accuracy is 82%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c77f0-ec94-4a58-8287-c0821ceac70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d8d12-d0ed-45d1-b0e6-d59aa701b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9694c-6829-4995-993e-4d1e6a250387",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1fe3d-4b73-4118-b3e7-067767a2523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bec9a-eac5-4a34-bf17-1e1c6a40bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc094285-525c-44aa-af20-790a28763437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602490d5-58ca-4f5d-84df-dfac6fcfb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534dfc5-1f47-4b63-bd65-cd02862de0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fdc67-0524-41af-9273-3c7e5d762f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f87314-06bf-4888-ba91-3c67393de1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a030328-f1dc-4d0a-9225-3131f1b6f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
