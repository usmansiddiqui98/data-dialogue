{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# Read the call data from the CSV file\n",
    "call_data = pd.read_csv('../../data/raw/call_data.csv')\n",
    "\n",
    "transcripts = {}\n",
    "\n",
    "# Iterate over the files in the transcripts directory\n",
    "for filename in os.listdir('../../data/raw/transcripts'):\n",
    "    # Get the SID from the filename\n",
    "    sid = os.path.splitext(filename)[0]\n",
    "    \n",
    "    with open(f'../../data/raw/transcripts/{filename}', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    lines = [re.sub(r'^\\d+.\\s', '', line.strip()) for line in lines]\n",
    "    transcripts[sid] = lines\n",
    "\n",
    "# Add the transcript data as a column to the call data\n",
    "call_data['transcript'] = call_data['SID'].map(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_data.to_csv('nooks_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have a small dataset of 198 calls labelled with whether there was a timing objection, and if so where in the call the timing objection is present (1-indexed).\n",
    "\n",
    "We want to use this dataset to train and evaluate a realtime timing-objection detector. To do this, we will formulate the problem as a simple time-series prediction. For every distinct moment of the call (every monologue, for simplicity), we pass as input to the call all the text transcript data from before that moment, and try to build a model that can predict whether a timing objection has occured in the portion of the call it has seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>monologues_so_far</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>CAa481788bab5e4fee93838fec4b49bd59</td>\n",
       "      <td>[[Prospect]  Paul speaking., [Sales Rep]  Hey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>CAa481788bab5e4fee93838fec4b49bd59</td>\n",
       "      <td>[[Prospect]  Paul speaking., [Sales Rep]  Hey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>CAa481788bab5e4fee93838fec4b49bd59</td>\n",
       "      <td>[[Prospect]  Paul speaking., [Sales Rep]  Hey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>CAa481788bab5e4fee93838fec4b49bd59</td>\n",
       "      <td>[[Prospect]  Paul speaking., [Sales Rep]  Hey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>CAa481788bab5e4fee93838fec4b49bd59</td>\n",
       "      <td>[[Prospect]  Paul speaking., [Sales Rep]  Hey,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     SID  \\\n",
       "0     CA77596bc061516d795f6a60fbd274cb0e   \n",
       "1     CA77596bc061516d795f6a60fbd274cb0e   \n",
       "2     CA77596bc061516d795f6a60fbd274cb0e   \n",
       "3     CA77596bc061516d795f6a60fbd274cb0e   \n",
       "4     CA77596bc061516d795f6a60fbd274cb0e   \n",
       "...                                  ...   \n",
       "3158  CAa481788bab5e4fee93838fec4b49bd59   \n",
       "3159  CAa481788bab5e4fee93838fec4b49bd59   \n",
       "3160  CAa481788bab5e4fee93838fec4b49bd59   \n",
       "3161  CAa481788bab5e4fee93838fec4b49bd59   \n",
       "3162  CAa481788bab5e4fee93838fec4b49bd59   \n",
       "\n",
       "                                      monologues_so_far  \n",
       "0     [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "1     [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "2     [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "3     [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "4     [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "...                                                 ...  \n",
       "3158  [[Prospect]  Paul speaking., [Sales Rep]  Hey,...  \n",
       "3159  [[Prospect]  Paul speaking., [Sales Rep]  Hey,...  \n",
       "3160  [[Prospect]  Paul speaking., [Sales Rep]  Hey,...  \n",
       "3161  [[Prospect]  Paul speaking., [Sales Rep]  Hey,...  \n",
       "3162  [[Prospect]  Paul speaking., [Sales Rep]  Hey,...  \n",
       "\n",
       "[3163 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the training set X and the target set Y\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Iterate over each call\n",
    "for index, row in call_data.iterrows():\n",
    "    # Get the SID and the transcript\n",
    "    sid = row['SID']\n",
    "    transcript = row['transcript']\n",
    "    timing_objection_index = row['Timing Objection Index']\n",
    "\n",
    "    # Iterate over each split point in the transcript\n",
    "    for i in range(2, len(transcript)):\n",
    "        # Create a new data point\n",
    "        data_point = {\n",
    "            'SID': sid,\n",
    "            'monologues_so_far': transcript[:i],\n",
    "        }\n",
    "        # Add the data point to the training set\n",
    "        X.append(data_point)\n",
    "\n",
    "        # Add the corresponding target value to the target set\n",
    "        Y.append(1 if timing_objection_index != \"None\" and i >= int(timing_objection_index) else 0)\n",
    "\n",
    "# Convert the training set and the target set to pandas DataFrames for easier manipulation\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.Series(Y)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've constructed our dataset of inputs and model targets, we can build a model to predict the target class (whether a timing objection has occured in the call so far or not.) \n",
    "\n",
    "Normally we would split the data into a non-overlapping train and test set and train a model on the train set, but for demonstration purposes we can build a data-free model that just relies on human context about what a \"timing objection\" means in sales. Because of the advanced capabilities of LLMs like GPT-4, we can transform this human context into a fairly reliable predictor of timing objections even without any labelled data, just using prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import yaml\n",
    "\n",
    "# Ask for an OpenAI API key to run this\n",
    "openai.api_key = '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'\n",
    "\n",
    "def predict_timing_objection(call):\n",
    "    # Join the monologues into a single string\n",
    "    call_so_far = '\\n'.join([f\"[{i}] {call}\" for i, call in enumerate(call['monologues_so_far'], start=1)])\n",
    "    system_prompt = f\"\"\"\n",
    "You are functioning as a virtual sales manager with the task of meticulously analyzing phone call transcripts between our Sales Representatives (Sales Rep) and potential clients (Prospect). Your role involves providing insight into the dynamics of the conversation, with a particular emphasis on identifying specific objections raised by the Prospect.\n",
    "\n",
    "The transcripts you will be examining are structured as follows.\n",
    "\n",
    "Each line of dialogue (where one speaker talks) is presented in the format:\n",
    "[Monologue Index] [Speaker]: [Monologue]\n",
    "\n",
    "Your task is to predict in real time whether the specific objection (described further below) happened given the text of the call so far.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    call_transcript = f\"\"\"\n",
    "###\n",
    "\n",
    "Here is the complete transcript of the phone call so far:\n",
    "{call_so_far}\n",
    "\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = \"\"\"\n",
    "Answer the following yes or no question based ONLY on the contents of the call transcript provided above. \n",
    "Does the call contain a timing objection? \n",
    "To provide clarity, a 'timing objection' refers to a scenario where the Prospect expresses interest in the product and is open to discussing its utilization within their company at a future date. However, they indicate that the current moment is not opportune for making purchasing decisions. This may be due to a variety of time-related factors such as the end of a financial quarter, the onboarding of new employees, ongoing layoffs, etc.\n",
    "\n",
    "Examples of phrases that might indicate timing objections:\n",
    "\"Now is not the right time\"\n",
    "\"Next quarter might be a better time to circle back\"\n",
    "\"Right now our focus is on this, but that might change in the future\"\n",
    "\"No way that we're buying anything this year, but next year maybe\"\n",
    "\n",
    "Please note that a 'timing objection' does not refer to instances where the Prospect indicates that it is simply a bad time for them to engage in the phone call itself. \n",
    "It specifically pertains to situations where there are external, time-bound factors affecting the Prospect’s ability or willingness to proceed with a purchasing decision.\n",
    "Furthermore, a 'timing objection' is not applicable if the Prospect categorically refuses to consider the product for reasons that are likely to be permanent or long-term, such as an established strategy, commitment to a competitor, size of the company (too small), or budgetary constraints.\n",
    "To reiterate, if the prospect says they are currently using a competitor but seem open to talking after the competitor's contract runs out, that does NOT count as a timing objection.\n",
    "\n",
    "Objections can only be said by prospects, so if the sales rep mentions something time-related, that should not be counted as an objection.\n",
    "\n",
    "Give your response in YAML format. The response should have the following fields:\n",
    "reason - A string value that explains your reasoning for the answer.\n",
    "monologueIndex - An integer value pointing to the first index of the monologue in the call transcript that justifies the answer to the question. Only provide this field if the answer was true.\n",
    "answer - A boolean value of true or false. True indicates that the answer to the question was \"yes\". False indicates that the answer to the question was \"no\".\n",
    "\n",
    "Here is an example of a well-formatted response using YAML format.\n",
    "---\n",
    "result:\n",
    "    reason: This is the reason why the answer to the question is true.\n",
    "    monologueIndex: 5\n",
    "    answer: true\n",
    "\n",
    "Thank you for your attention to detail and thorough analysis. Your insights are invaluable to our continuous efforts in enhancing our sales strategies and understanding client needs more effectively.\n",
    "\n",
    "Your response:\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": call_transcript},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    # print (response.choices[0][\"message\"][\"content\"])\n",
    "    # Extract the predicted output\n",
    "    predicted_output = list(yaml.safe_load_all(response.choices[0][\"message\"][\"content\"]))[0]\n",
    "\n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                  | 0/3163 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create a ThreadPoolExecutor\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Use the executor to apply the function to every row in X_balanced\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_predict_timing_objection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitertuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Separate the results and the times\u001b[39;00m\n\u001b[1;32m     30\u001b[0m Y_pred_list, times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mapply_predict_timing_objection\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Apply predict_timing_objection\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_timing_objection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Measure the end time\u001b[39;00m\n\u001b[1;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m, in \u001b[0;36mpredict_timing_objection\u001b[0;34m(call)\u001b[0m\n\u001b[1;32m     22\u001b[0m     call_transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m###\u001b[39m\n\u001b[1;32m     24\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m###\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mAnswer the following yes or no question based ONLY on the contents of the call transcript provided above. \u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mDoes the call contain a timing objection? \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124mYour response:\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 66\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_transcript\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# print (response.choices[0][\"message\"][\"content\"])\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Extract the predicted output\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     predicted_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(yaml\u001b[38;5;241m.\u001b[39msafe_load_all(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a function that applies predict_timing_objection to a row and measures the time taken\n",
    "def apply_predict_timing_objection(row):\n",
    "    # Convert the row into a dictionary manually\n",
    "    row_dict = {X.columns[i]: value for i, value in enumerate(row)}\n",
    "    \n",
    "    # Measure the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply predict_timing_objection\n",
    "    result = predict_timing_objection(row_dict)\n",
    "    \n",
    "    # Measure the end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate the time taken\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    return result, time_taken\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Use the executor to apply the function to every row in X_balanced\n",
    "    results = list(tqdm(executor.map(apply_predict_timing_objection, X.itertuples(index=False)), total=len(X)))\n",
    "\n",
    "# Separate the results and the times\n",
    "Y_pred_list, times = zip(*results)\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "Y_pred = pd.DataFrame([result['result']['answer'] for result in Y_pred_list])\n",
    "Y_reason = pd.DataFrame([result['result']['reason'] for result in Y_pred_list])\n",
    "\n",
    "\n",
    "# Print the average time taken per invocation\n",
    "print('Average time taken per invocation:', sum(times) / len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8493150684931506\n",
      "Recall: 0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Compute the precision score\n",
    "precision = precision_score(Y, Y_pred)\n",
    "print('Precision:', precision)\n",
    "\n",
    "# Compute the recall score\n",
    "recall = recall_score(Y, Y_pred)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision over 0.8 and Recall over 0.9 is pretty good for this type of problem! (Especially when timing objections can be somewhat ambiguously labelled.)\n",
    "\n",
    "However, taking 11s on average to call the model to predict a timing objection is MUCH too slow - if this model is intended to surface responses to timing objections in real time to the user, then you need **less than 0.25s latency**. That isn't possible by calling out to an external service like OpenAI's GPT-4, but might be possible through running smaller, lower-latency local models.\n",
    "\n",
    "Can you build a model that achieves comparable precision and recall to the GPT-4 based model presented here, but with sub 0.25s latency per invocation? \n",
    "\n",
    "Anything is fair game while building the low-latency model, including injecting additional human knowledge and sales context, data augmentation or generation, using external services or off the shelf pretrained models, labelling additional data, and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
