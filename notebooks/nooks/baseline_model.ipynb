{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b776a019-93bb-45b7-84e7-9d8d70fc8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import contractions\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers.utils.logging\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daf8e653-3313-4e81-a169-18ee44849364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the call data from the CSV file\n",
    "call_data = pd.read_csv('../../data/raw/call_data.csv')\n",
    "\n",
    "transcripts = {}\n",
    "\n",
    "# Iterate over the files in the transcripts directory\n",
    "for filename in os.listdir('../../data/raw/transcripts'):\n",
    "    # Get the SID from the filename\n",
    "    sid = os.path.splitext(filename)[0]\n",
    "    \n",
    "    with open(f'../../data/raw/transcripts/{filename}', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    lines = [re.sub(r'^\\d+.\\s', '', line.strip()) for line in lines]\n",
    "    transcripts[sid] = lines\n",
    "\n",
    "# Add the transcript data as a column to the call data\n",
    "call_data['transcript'] = call_data['SID'].map(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9d85df8-985c-417a-a3d3-9753ee474efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>Had Timing Objection</th>\n",
       "      <th>Timing Objection Index</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAd8395ea9fec545909e633bba6a8eb643</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAf15429ca373443cd6a6a88573fe16f98</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Drake, this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA631c8faf6571f057e34bc12073da9f9c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  File perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAbb4454527ef392d377ffd37a5bb00669</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SID  Had Timing Objection  \\\n",
       "0  CA77596bc061516d795f6a60fbd274cb0e                 False   \n",
       "1  CAd8395ea9fec545909e633bba6a8eb643                 False   \n",
       "2  CAf15429ca373443cd6a6a88573fe16f98                  True   \n",
       "3  CA631c8faf6571f057e34bc12073da9f9c                 False   \n",
       "4  CAbb4454527ef392d377ffd37a5bb00669                  True   \n",
       "\n",
       "  Timing Objection Index                                         transcript  \n",
       "0                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...  \n",
       "1                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...  \n",
       "2                      9  [[Prospect]  Hello?, [Sales Rep]  Drake, this ...  \n",
       "3                   None  [[Prospect]  Hello?, [Sales Rep]  File perform...  \n",
       "4                     35  [[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6468d696-e632-4ab1-ad35-8c09ea9d0771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   SID                     198 non-null    object\n",
      " 1   Had Timing Objection    198 non-null    bool  \n",
      " 2   Timing Objection Index  198 non-null    object\n",
      " 3   transcript              198 non-null    object\n",
      " 4   flattened_transcript    198 non-null    object\n",
      " 5   cleaned_transcript      198 non-null    object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 8.1+ KB\n"
     ]
    }
   ],
   "source": [
    "call_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fc870a2-c9ee-4d10-a0f8-0df218dfc58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    164\n",
       "True      34\n",
       "Name: Had Timing Objection, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of the target variable\n",
    "class_distribution = call_data['Had Timing Objection'].value_counts()\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d675a1-5753-41a6-a124-e7a9f5645ed0",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43548df3-5650-4eff-a802-49a7309db51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary package downloads\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "\n",
    "stopwords = [\n",
    "    \"a\",\n",
    "    \"an\",\n",
    "    \"and\",\n",
    "    \"are\",\n",
    "    \"as\",\n",
    "    \"at\",\n",
    "    \"be\",\n",
    "    \"by\",\n",
    "    \"can\",\n",
    "    \"could\",\n",
    "    \"did\",\n",
    "    \"do\",\n",
    "    \"does\",\n",
    "    \"for\",\n",
    "    \"from\",\n",
    "    \"had\",\n",
    "    \"has\",\n",
    "    \"have\",\n",
    "    \"he\",\n",
    "    \"hence\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"if\",\n",
    "    \"in\",\n",
    "    \"is\",\n",
    "    \"it\",\n",
    "    \"its\",\n",
    "    # \"may\",\n",
    "    # \"might\",\n",
    "    # \"must\",\n",
    "    \"of\",\n",
    "    \"on\",\n",
    "    \"or\",\n",
    "    \"shall\",\n",
    "    \"should\",\n",
    "    \"since\",\n",
    "    \"so\",\n",
    "    \"some\",\n",
    "    \"such\",\n",
    "    \"that\",\n",
    "    \"the\",\n",
    "    \"their\",\n",
    "    \"them\",\n",
    "    \"then\",\n",
    "    \"there\",\n",
    "    \"these\",\n",
    "    \"they\",\n",
    "    \"this\",\n",
    "    \"those\",\n",
    "    \"to\",\n",
    "    \"was\",\n",
    "    \"we\",\n",
    "    \"were\",\n",
    "    \"when\",\n",
    "    \"where\",\n",
    "    \"which\",\n",
    "    \"while\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"whose\",\n",
    "    \"will\",\n",
    "    \"with\",\n",
    "    \"would\",\n",
    "    \"yet\",\n",
    "    \"you\",\n",
    "    \"your\",\n",
    "    \"yours\",\n",
    "    \"about\",\n",
    "    \"above\",\n",
    "    \"across\",\n",
    "    \"after\",\n",
    "    \"against\",\n",
    "    \"along\",\n",
    "    \"among\",\n",
    "    \"around\",\n",
    "    \"before\",\n",
    "    \"behind\",\n",
    "    \"below\",\n",
    "    \"beneath\",\n",
    "    \"beside\",\n",
    "    \"between\",\n",
    "    \"beyond\",\n",
    "    \"during\",\n",
    "    \"inside\",\n",
    "    \"into\",\n",
    "    \"near\",\n",
    "    \"outside\",\n",
    "    \"over\",\n",
    "    \"through\",\n",
    "    \"under\",\n",
    "    \"upon\",\n",
    "    \"within\",\n",
    "    \"without\",\n",
    "    \"been\",\n",
    "    \"having\",\n",
    "    \"once\",\n",
    "    \"other\",\n",
    "    \"until\",\n",
    "    \"more\",\n",
    "    \"less\",\n",
    "    \"own\",\n",
    "    \"also\",\n",
    "    \"each\",\n",
    "    \"every\",\n",
    "    \"any\",\n",
    "    \"all\",\n",
    "    \"some\",\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"four\",\n",
    "    \"five\",\n",
    "    \"six\",\n",
    "    \"seven\",\n",
    "    \"eight\",\n",
    "    \"nine\",\n",
    "    \"ten\",\n",
    "    \"many\",\n",
    "    \"several\",\n",
    "    \"few\",\n",
    "    \"less\",\n",
    "    \"more\",\n",
    "    \"most\",\n",
    "    \"several\",\n",
    "    \"how\",\n",
    "    \"anyway\",\n",
    "    \"however\",\n",
    "    \"just\",\n",
    "    \"quite\",\n",
    "    \"i\",\n",
    "]\n",
    "\n",
    "stopwords = list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5daada7f-390d-4f31-9f83-0b7b3f4b014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>Had Timing Objection</th>\n",
       "      <th>Timing Objection Index</th>\n",
       "      <th>transcript</th>\n",
       "      <th>flattened_transcript</th>\n",
       "      <th>cleaned_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey John Hey John It...</td>\n",
       "      <td>prospect hello sale rep hey john hey john s s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAd8395ea9fec545909e633bba6a8eb643</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey Ivan Skyler with...</td>\n",
       "      <td>prospect hello sale rep hey ivan skyler nook h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAf15429ca373443cd6a6a88573fe16f98</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Drake, this ...</td>\n",
       "      <td>Prospect Hello Sales Rep Drake this is Josh w...</td>\n",
       "      <td>prospect hello sale rep drake josh nook s s tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA631c8faf6571f057e34bc12073da9f9c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  File perform...</td>\n",
       "      <td>Prospect Hello Sales Rep File performance Hey...</td>\n",
       "      <td>prospect hello sale rep file performance hey a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAbb4454527ef392d377ffd37a5bb00669</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey Sean It s Patric...</td>\n",
       "      <td>prospect hello sale rep hey sean s patrick cal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SID  Had Timing Objection  \\\n",
       "0  CA77596bc061516d795f6a60fbd274cb0e                 False   \n",
       "1  CAd8395ea9fec545909e633bba6a8eb643                 False   \n",
       "2  CAf15429ca373443cd6a6a88573fe16f98                  True   \n",
       "3  CA631c8faf6571f057e34bc12073da9f9c                 False   \n",
       "4  CAbb4454527ef392d377ffd37a5bb00669                  True   \n",
       "\n",
       "  Timing Objection Index                                         transcript  \\\n",
       "0                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...   \n",
       "1                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...   \n",
       "2                      9  [[Prospect]  Hello?, [Sales Rep]  Drake, this ...   \n",
       "3                   None  [[Prospect]  Hello?, [Sales Rep]  File perform...   \n",
       "4                     35  [[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...   \n",
       "\n",
       "                                flattened_transcript  \\\n",
       "0   Prospect Hello Sales Rep Hey John Hey John It...   \n",
       "1   Prospect Hello Sales Rep Hey Ivan Skyler with...   \n",
       "2   Prospect Hello Sales Rep Drake this is Josh w...   \n",
       "3   Prospect Hello Sales Rep File performance Hey...   \n",
       "4   Prospect Hello Sales Rep Hey Sean It s Patric...   \n",
       "\n",
       "                                  cleaned_transcript  \n",
       "0  prospect hello sale rep hey john hey john s s ...  \n",
       "1  prospect hello sale rep hey ivan skyler nook h...  \n",
       "2  prospect hello sale rep drake josh nook s s tu...  \n",
       "3  prospect hello sale rep file performance hey a...  \n",
       "4  prospect hello sale rep hey sean s patrick cal...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_sentence(sentence, stop_words):\n",
    "    \"\"\"\n",
    "    Clean a single string by removing tags, resolving contractions, removing digits and special characters,\n",
    "    tokenizing, changing to lower case and removing punctuations, removing stop words, finding the POS tag\n",
    "    for each token, and lemmatizing each token.\n",
    "\n",
    "    Parameters:\n",
    "        sentence (str):A single string to be cleaned.\n",
    "\n",
    "        stop_words (list): A list of stop words to be removed from the string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned string.\n",
    "    \"\"\"\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith(\"J\"):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith(\"V\"):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith(\"N\"):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith(\"R\"):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = re.sub(r\"<.*?>|Length::\\d+:\\d+Mins\", \" \", sentence)\n",
    "    sentence = contractions.fix(sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z\\s]\", \" \", sentence)\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    pos_tagged = nltk.pos_tag(words)\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "def truncate_to_512(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    pos_tagged = nltk.pos_tag(words)\n",
    "    nouns_adjectives = [word for word, tag in pos_tagged if tag.startswith(\"N\") or tag.startswith(\"J\")]\n",
    "    remaining = [word for word in words if word not in nouns_adjectives]\n",
    "    if len(nouns_adjectives) <= 512:\n",
    "        combined = nouns_adjectives + remaining[: 512 - len(nouns_adjectives)]\n",
    "    else:\n",
    "        combined = nouns_adjectives[:512]\n",
    "    return \" \".join(combined)\n",
    "\n",
    "def preprocess_text_from_list(text_list):\n",
    "    # Join the list elements into a single string\n",
    "    combined_text = ' '.join(text_list)\n",
    "    # Remove special characters and numbers\n",
    "    combined_text = re.sub(r'\\W+|\\d+', ' ', combined_text)\n",
    "    return combined_text\n",
    "    \n",
    "call_data['flattened_transcript'] = call_data['transcript'].apply(preprocess_text_from_list)\n",
    "call_data['cleaned_transcript'] = call_data['flattened_transcript'].apply(lambda x: clean_sentence(x, stopwords))\n",
    "#call_data['truncated_transcript'] = call_data['cleaned_transcript'].apply(truncate_to_512)\n",
    "\n",
    "call_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966be388-0c7c-456f-83a4-f54daa4930ce",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02180c2d-4acc-40d9-8fc6-94d11b06d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_polarity_score(sentence):\n",
    "    \"\"\"\n",
    "    Calculate the compound polarity score of a sentence using VaderSentiment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to be analyzed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The compound polarity score of the sentence.\n",
    "    \"\"\"\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    score = sid_obj.polarity_scores(sentence)[\"compound\"]\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_subjectivity(sentence):\n",
    "    \"\"\"\n",
    "    Calculate the subjectivity score of a sentence using TextBlob.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to be analyzed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The subjectivity score of the sentence.\n",
    "    \"\"\"\n",
    "    return round(TextBlob(sentence).sentiment.subjectivity, 6)\n",
    "\n",
    "\n",
    "def count_pos_neg_neutral(sentence):\n",
    "    \"\"\"\n",
    "    Count the number of positive, negative, and neutral words in a sentence using VaderSentiment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to be analyzed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of three integers representing the count of positive, negative, and neutral words in the sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    text_split = sentence.split()\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos_word_list = []\n",
    "    neu_word_list = []\n",
    "    neg_word_list = []\n",
    "\n",
    "    for word in text_split:\n",
    "        if (sid.polarity_scores(word)[\"compound\"]) >= 0.5:\n",
    "            pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)[\"compound\"]) <= -0.5:\n",
    "            neg_word_list.append(word)\n",
    "        else:\n",
    "            neu_word_list.append(word)\n",
    "    return [len(pos_word_list), len(neg_word_list), len(neu_word_list)]\n",
    "\n",
    "    # Define function to count number of lowercase\n",
    "\n",
    "\n",
    "def count_lower(sentence):\n",
    "    \"\"\"\n",
    "    Count the number of lowercase words in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to be analyzed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of lowercase words in the sentence.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if not word.isupper():  # eg Real is considered lowercase\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Define function to count number of uppercase\n",
    "def count_upper(sentence):\n",
    "    \"\"\"\n",
    "    Count the number of uppercase words in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        The sentence to be analyzed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of uppercase words in the sentence.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word.isupper():\n",
    "            if len(word) > 1:  # exclude one letter words eg 'I'\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Define function to list uppercase words\n",
    "def uppercase_list(sentence):\n",
    "    \"\"\"\n",
    "    Get a list of uppercase words in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Input sentence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A comma-separated string of uppercase words in the sentence.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    uppercase = []\n",
    "    for word in words:\n",
    "        if word.isupper():\n",
    "            if len(word) > 1:  # exclude one letter words eg 'I'\n",
    "                uppercase.append(word)\n",
    "    uppercase = \", \".join(uppercase)\n",
    "    return uppercase\n",
    "\n",
    "\n",
    "# Define function to get uppercase:total tokens ratio\n",
    "def uppercase_ratio(sentence):\n",
    "    \"\"\"\n",
    "    Get the ratio of uppercase words to total tokens in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Input sentence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The ratio of uppercase words to total tokens, rounded to 6 decimal places.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word.isupper():\n",
    "            if len(word) > 1:  # exclude 'I'\n",
    "                count += 1\n",
    "    ratio = count / len(words)\n",
    "    ratio = round(ratio, 6)\n",
    "    return ratio\n",
    "\n",
    "\n",
    "# Define function to count number of punctuations\n",
    "def count_punc(sentence):\n",
    "    \"\"\"\n",
    "    Count the number of punctuations in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Input sentence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of punctuations in the sentence.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in string.punctuation:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def pos_tags(sentence):\n",
    "    \"\"\"\n",
    "    Get the part-of-speech (POS) tags of the words in a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Input sentence.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        A list of tuples, where each tuple contains a word and its corresponding POS tag.\n",
    "    \"\"\"\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
    "    tagged = nltk.pos_tag(tokenized_sentence)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73fcb77f-9790-4e41-bb7b-fce6137b9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the feature engineering functions to your DataFrame\n",
    "call_data['compound_polarity'] = call_data['flattened_transcript'].apply(compound_polarity_score)\n",
    "call_data['subjectivity'] = call_data['flattened_transcript'].apply(get_subjectivity)\n",
    "call_data[['num_positive', 'num_negative', 'num_neutral']] = call_data['flattened_transcript'].apply(count_pos_neg_neutral).apply(pd.Series)\n",
    "call_data['lowercase_count'] = call_data['flattened_transcript'].apply(count_lower)\n",
    "call_data['uppercase_count'] = call_data['flattened_transcript'].apply(count_upper)\n",
    "call_data['pos_tag'] = call_data['flattened_transcript'].apply(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12b9bcd6-92df-45f2-a32e-b306756da677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>Had Timing Objection</th>\n",
       "      <th>Timing Objection Index</th>\n",
       "      <th>transcript</th>\n",
       "      <th>flattened_transcript</th>\n",
       "      <th>cleaned_transcript</th>\n",
       "      <th>compound_polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>num_positive</th>\n",
       "      <th>num_negative</th>\n",
       "      <th>num_neutral</th>\n",
       "      <th>lowercase_count</th>\n",
       "      <th>uppercase_count</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA77596bc061516d795f6a60fbd274cb0e</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, John. H...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey John Hey John It...</td>\n",
       "      <td>prospect hello sale rep hey john hey john s s ...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.501447</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1605</td>\n",
       "      <td>1555</td>\n",
       "      <td>9</td>\n",
       "      <td>[(prospect, JJ), (hello, NN), (sales, NNS), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAd8395ea9fec545909e633bba6a8eb643</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey Ivan Skyler with...</td>\n",
       "      <td>prospect hello sale rep hey ivan skyler nook h...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.525811</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1575</td>\n",
       "      <td>1476</td>\n",
       "      <td>13</td>\n",
       "      <td>[(prospect, JJ), (hello, NN), (sales, NNS), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAf15429ca373443cd6a6a88573fe16f98</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Drake, this ...</td>\n",
       "      <td>Prospect Hello Sales Rep Drake this is Josh w...</td>\n",
       "      <td>prospect hello sale rep drake josh nook s s tu...</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.611293</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>586</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>[(prospect, JJ), (hello, NN), (sales, NNS), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA631c8faf6571f057e34bc12073da9f9c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  File perform...</td>\n",
       "      <td>Prospect Hello Sales Rep File performance Hey...</td>\n",
       "      <td>prospect hello sale rep file performance hey a...</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.517547</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>277</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>[(prospect, JJ), (hello, NN), (sales, NNS), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAbb4454527ef392d377ffd37a5bb00669</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>[[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...</td>\n",
       "      <td>Prospect Hello Sales Rep Hey Sean It s Patric...</td>\n",
       "      <td>prospect hello sale rep hey sean s patrick cal...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.490979</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>1900</td>\n",
       "      <td>6</td>\n",
       "      <td>[(prospect, JJ), (hello, NN), (sales, NNS), (r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SID  Had Timing Objection  \\\n",
       "0  CA77596bc061516d795f6a60fbd274cb0e                 False   \n",
       "1  CAd8395ea9fec545909e633bba6a8eb643                 False   \n",
       "2  CAf15429ca373443cd6a6a88573fe16f98                  True   \n",
       "3  CA631c8faf6571f057e34bc12073da9f9c                 False   \n",
       "4  CAbb4454527ef392d377ffd37a5bb00669                  True   \n",
       "\n",
       "  Timing Objection Index                                         transcript  \\\n",
       "0                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, John. H...   \n",
       "1                   None  [[Prospect]  Hello?, [Sales Rep]  Hey, Ivan. S...   \n",
       "2                      9  [[Prospect]  Hello?, [Sales Rep]  Drake, this ...   \n",
       "3                   None  [[Prospect]  Hello?, [Sales Rep]  File perform...   \n",
       "4                     35  [[Prospect]  Hello?, [Sales Rep]  Hey, Sean. I...   \n",
       "\n",
       "                                flattened_transcript  \\\n",
       "0   Prospect Hello Sales Rep Hey John Hey John It...   \n",
       "1   Prospect Hello Sales Rep Hey Ivan Skyler with...   \n",
       "2   Prospect Hello Sales Rep Drake this is Josh w...   \n",
       "3   Prospect Hello Sales Rep File performance Hey...   \n",
       "4   Prospect Hello Sales Rep Hey Sean It s Patric...   \n",
       "\n",
       "                                  cleaned_transcript  compound_polarity  \\\n",
       "0  prospect hello sale rep hey john hey john s s ...             0.9999   \n",
       "1  prospect hello sale rep hey ivan skyler nook h...             0.9999   \n",
       "2  prospect hello sale rep drake josh nook s s tu...             0.9996   \n",
       "3  prospect hello sale rep file performance hey a...             0.9920   \n",
       "4  prospect hello sale rep hey sean s patrick cal...             0.9999   \n",
       "\n",
       "   subjectivity  num_positive  num_negative  num_neutral  lowercase_count  \\\n",
       "0      0.501447             9             0         1605             1555   \n",
       "1      0.525811             8             3         1575             1476   \n",
       "2      0.611293             5             1          586              555   \n",
       "3      0.517547             3             2          277              284   \n",
       "4      0.490979            18             0         1955             1900   \n",
       "\n",
       "   uppercase_count                                            pos_tag  \n",
       "0                9  [(prospect, JJ), (hello, NN), (sales, NNS), (r...  \n",
       "1               13  [(prospect, JJ), (hello, NN), (sales, NNS), (r...  \n",
       "2                0  [(prospect, JJ), (hello, NN), (sales, NNS), (r...  \n",
       "3                0  [(prospect, JJ), (hello, NN), (sales, NNS), (r...  \n",
       "4                6  [(prospect, JJ), (hello, NN), (sales, NNS), (r...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e17a95-60d0-470f-9350-4f7b12239187",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17270216-ffb1-4ce6-bc68-391fa468ef3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'clean_transcript'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clean_transcript'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m) \u001b[38;5;66;03m# Limiting to 5000 features for simplicity and speed\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m X_train_bow \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_transcript\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     10\u001b[0m X_train_bow \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_bow\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n\u001b[1;32m     12\u001b[0m X_train_clean \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/data-dialogue/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clean_transcript'"
     ]
    }
   ],
   "source": [
    "X = call_data.drop([\"Had Timing Objection\"], axis=1)\n",
    "y = call_data['Had Timing Objection']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000) # Limiting to 5000 features for simplicity and speed\n",
    "\n",
    "X_train_bow = tfidf.fit_transform(X_train['cleaned_transcript'])\n",
    "X_train_bow = pd.DataFrame(X_train_bow.toarray(), columns=self.vectorizer.get_feature_names_out())\n",
    "\n",
    "X_train_clean = X_train.drop([\"flattened_transcript\", \"cleaned_transcript\",], axis=1)\n",
    "X_train_concat = pd.concat([X_train_clean, X_train_bow], axis=1)\n",
    "X_train_concat = X_train_concat.loc[:, ~X_train_concat.columns.duplicated()].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff733253-831c-4718-ab59-3ccd0fada62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af8f26-b26f-46d4-82e2-037e38a135f5",
   "metadata": {},
   "source": [
    "## Baseline model using tf-idf and log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "059983ee-d562-4e43-a17f-6454dac963e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 1.0, 0.00019407272338867188)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log reg with class weights as data is imbalanced\n",
    "log_reg_balanced = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# train\n",
    "log_reg_balanced.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "start_time_balanced = time.time()\n",
    "y_pred_balanced = log_reg_balanced.predict(X_test)\n",
    "end_time_balanced = time.time()\n",
    "\n",
    "# time taken for prediction\n",
    "prediction_time_balanced = end_time_balanced - start_time_balanced\n",
    "\n",
    "# precision and recall\n",
    "precision_balanced = precision_score(y_test, y_pred_balanced)\n",
    "recall_balanced = recall_score(y_test, y_pred_balanced)\n",
    "\n",
    "precision_balanced, recall_balanced, prediction_time_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ad923-6ba1-4dfc-9c99-f8b6cc0770dd",
   "metadata": {},
   "source": [
    "### Log reg with grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f8146e4-f016-4c0f-b3e0-5b9f27e8d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 100, 'solver': 'liblinear'},\n",
       " 0.2,\n",
       " 0.3333333333333333,\n",
       " 0.0001049041748046875)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # regularization strength\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs']  # optimizationa algo\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, \n",
    "                           scoring='precision', cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "log_reg_tuned = LogisticRegression(class_weight='balanced', **best_params)\n",
    "log_reg_tuned.fit(X_train, y_train)\n",
    "\n",
    "start_time_tuned = time.time()\n",
    "y_pred_tuned = log_reg_tuned.predict(X_test)\n",
    "end_time_tuned = time.time()\n",
    "\n",
    "prediction_time_tuned = end_time_tuned - start_time_tuned\n",
    "\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "\n",
    "best_params, precision_tuned, recall_tuned, prediction_time_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66606d95-2e14-4802-96ae-67d2dff599f9",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca93d94-2e73-4600-9de0-ad06da0a029c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2222222222222222, 0.6666666666666666, 0.004116058349609375)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVC(class_weight='balanced', probability=True)\n",
    "\n",
    "# Train\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "start_time_svm = time.time()\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "end_time_svm = time.time()\n",
    "\n",
    "# time taken for prediction\n",
    "prediction_time_svm = end_time_svm - start_time_svm\n",
    "\n",
    "# precision and recall\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "\n",
    "precision_svm, recall_svm, prediction_time_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f5dd3-cf85-4a9b-b516-720d2fb87b9f",
   "metadata": {},
   "source": [
    "## Using Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b337f14a-d8be-4b2f-a967-85da324470c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.18181818181818182, 0.6666666666666666), (0.25, 0.6666666666666666))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram = TfidfVectorizer(max_features=5000, ngram_range=(1, 3)) # unigrams, bigrams, and trigrams\n",
    "\n",
    "X_ngram = tfidf_ngram.fit_transform(call_data['clean_transcript'])\n",
    "\n",
    "X_train_ngram, X_test_ngram, y_train, y_test = train_test_split(X_ngram, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg_ngram = LogisticRegression(class_weight='balanced')\n",
    "log_reg_ngram.fit(X_train_ngram, y_train)\n",
    "\n",
    "svm_model_ngram = SVC(class_weight='balanced', probability=True)\n",
    "svm_model_ngram.fit(X_train_ngram, y_train)\n",
    "\n",
    "y_pred_log_reg_ngram = log_reg_ngram.predict(X_test_ngram)\n",
    "precision_log_reg_ngram = precision_score(y_test, y_pred_log_reg_ngram)\n",
    "recall_log_reg_ngram = recall_score(y_test, y_pred_log_reg_ngram)\n",
    "\n",
    "y_pred_svm_ngram = svm_model_ngram.predict(X_test_ngram)\n",
    "precision_svm_ngram = precision_score(y_test, y_pred_svm_ngram)\n",
    "recall_svm_ngram = recall_score(y_test, y_pred_svm_ngram)\n",
    "\n",
    "(precision_log_reg_ngram, recall_log_reg_ngram), (precision_svm_ngram, recall_svm_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a4865-3a45-4ef1-b1b8-2b52eba47cb2",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddd14735-2bd4-4e51-abc8-f86a263ebfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.6666666666666666, 0.0009341239929199219)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=(len(y)-sum(y))/sum(y))\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train_ngram, y_train)\n",
    "\n",
    "# Predict on the test set with the XGBoost model\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb_model.predict(X_test_ngram)\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "# Calculate the time taken for prediction\n",
    "prediction_time_xgb = end_time_xgb - start_time_xgb\n",
    "\n",
    "# Calculate precision and recall for the XGBoost model\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "\n",
    "precision_xgb, recall_xgb, prediction_time_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44925973-8831-4b65-8aab-ebfa7c0665fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
