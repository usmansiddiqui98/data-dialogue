import os
import pickle

from bertopic import BERTopic
from hdbscan import HDBSCAN
from sentence_transformers import SentenceTransformer
from umap import UMAP


class BertTopic:
    """
    A class for generating topic models using BERT embeddings.

    Attributes:
    -----------

    data (pandas.DataFrame):
        The input data as a pandas dataframe.
    preprocessor (Preprocessor):
        An instance of Preprocessor class used for text pre-processing.
    embeddings (numpy.ndarray):
        An array of BERT embeddings for each document.
    topics (list):
        A list of topic labels for each document.
    probabilities (numpy.ndarray):
        An array of probabilities for each topic in each document.
    topic_model (BERTopic):
        An instance of BERTopic model for generating topics.
    """

    def __init__(self, data):
        """
        Constructs all necessary attributes for the BertTopic object.

        Parameters:
            data (pandas.DataFrame):
                The input data as a pandas dataframe.
        """
        self.data = data
        self.embeddings = None
        self.topics = None
        self.probabilities = None
        self.topic_model = None

    def prepare_embeddings(self):
        """
        Generates BERT embeddings for input data and saves them to a file for future use.
        """
        BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
        embeddings_file = os.path.join(BASE_DIR, "data/embeddings/BERTopic_embeddings.pickle")

        if os.path.exists(embeddings_file):
            print("Loading existing embeddings...")
            with open(embeddings_file, "rb") as pkl:
                self.embeddings = pickle.load(pkl)
        else:
            print("Creating new embeddings...")
            sentence_model = SentenceTransformer("all-MiniLM-L12-v2")
            self.embeddings = sentence_model.encode(self.data["cleaned_text"], show_progress_bar=True)

            # save embeddings
            with open(embeddings_file, "wb") as pkl:
                pickle.dump(self.embeddings, pkl)

    def run_bertopic(self):
        """
        Create a BERTopic model using UMAP and HDBSCAN for dimensionality reduction and clustering,
        and fit the model on the cleaned text data and embeddings.

        Attributes
        ----------
        self.topic_model : BERTopic instance
            The BERTopic model fitted on the cleaned text data and embeddings.
        self.topics : list
            The list of topics generated by the BERTopic model.
        self.probabilities : list
            The list of probabilities associated with each topic for each document.

        Notes
        -----
        This method does not return any value; it updates the instance attributes.
        """
        umap_model = UMAP(n_neighbors=100, n_components=3, min_dist=0.0, metric="cosine", random_state=4263)

        hdbscan_model = HDBSCAN(min_cluster_size=50, min_samples=20, metric="euclidean", prediction_data=True)

        self.topic_model = BERTopic(
            hdbscan_model=hdbscan_model,
            umap_model=umap_model,
            language="english",
            calculate_probabilities=True,
            nr_topics="auto",
        )

        self.topics, self.probabilities = self.topic_model.fit_transform(self.data["cleaned_text"], self.embeddings)

    def get_topics(self):
        """
        Get the topics and their associated words and scores from the BERTopic model.

        Returns
        -------
        topic_words : dict
            A dictionary where keys are the topic IDs and values are dictionaries
            containing the word and score pairs associated with each topic.
        """
        topic_words = {}
        topic_info = self.topic_model.get_topic_info()
        for index, row in topic_info.iterrows():
            topic_id = row["Topic"]
            words_scores = self.topic_model.get_topic(topic_id)
            words_scores_dict = {word: score for word, score in words_scores}
            topic_words[topic_id] = words_scores_dict
        return topic_words

    def visualize(self):
        model = self.topic_model
        # model.visualize_barchart(top_n_topics)
        term_rank_viz = model.visualize_term_rank()
        topic_viz = model.visualize_topics()
        topics_over_time = model.topics_over_time(self.data["cleaned_text"], self.data["time"])
        time_viz = model.visualize_topics_over_time(topics_over_time)
        sentiment = [i for i in self.data["sentiment"]]
        topics_by_sentiment = model.topics_per_class(self.data["cleaned_text"], classes=sentiment)
        topic_per_class_viz = model.visualize_topics_per_class(topics_by_sentiment)
        return term_rank_viz, topic_viz, time_viz, topic_per_class_viz
